Prereqs:
- AWS CLI
- eksctl
- kubectl

### Use eksctl to create the cluster
```sh
$ eksctl create cluster -f cluster.yaml
```
kubectl apply -f https://s3.us-west-2.amazonaws.com/amazon-eks/docs/eks-console-full-access.yaml
eksctl create iamidentitymapping -f cluster-identities.yaml --no-duplicate-arns

Scale the nodegroups to 1
``
eksctl scale nodegroup --cluster vllm-cluster --name gpu-nodegroup --nodes 1
eksctl scale nodegroup --cluster vllm-cluster --name monitoring-nodegroup --nodes 1
```

2. Install the NVIDIA device plugin? mihgt not be needed with eksctl, see docs
```
$ kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.15.1/nvidia-device-plugin.yml
```

```
helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
helm install --generate-name nvdp/nvidia-device-plugin
```

Create the Hugging Face secret
```
kubectl create secret generic huggingface-secret --from-literal=hf_token='YOUR_HUGGING_FACE_TOKEN' --namespace=vllm-staging
```

Apply manifests:
```
kubectl apply -f deployment.yaml
# check status
kubectl get pods -w
kubectl logs -f <your-pod-name>

kubectl apply -f service.yaml
# check status
kubectl get service vllm-service
```

Verify
```
# Check pod status (it will be 'ContainerCreating' then 'Running')
kubectl get pods -w

# Check the logs of the pod to see download progress and server startup
kubectl logs -f <your-pod-name>
```

Get external URL
```
kubectl get service vllm-service
```

test:
```
curl <external-url>/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
    "prompt": "What is deep learning?",
    "max_tokens": 100,
    "temperature": 0.7
    }'
```


Scale to 0 to save money!
```
eksctl scale nodegroup --cluster vllm-cluster --name gpu-nodegroup --nodes 0 --region us-east-1
```

Scale back to 1:
```

# verify that it's up
kubectl get nodes -w
```


Note, with g5.xlarge, went up to about 70 RPS.A



## adding monitoring

https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
```sh
# add the repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

helm install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace


helm repo add gpu-helm-charts https://nvidia.github.io/dcgm-exporter/helm-charts
helm repo update
helm install dcgm-exporter gpu-helm-charts/dcgm-exporter -n monitoring

kubectl apply -f deployment.yaml
kubectl port-forward svc/prometheus-grafana 3000:80 -n monitoring

```


for prometheus:
```
kube-prometheus-stack has been installed. Check its status by running:
  kubectl --namespace monitoring get pods -l "release=prometheus"

Get Grafana 'admin' user password by running:

kubectl --namespace monitoring get secrets prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d ; echo

Access Grafana local instance:

export POD_NAME=$(kubectl --namespace monitoring get pod -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=prometheus" -oname)
kubectl --namespace monitoring port-forward $POD_NAME 3000
```
for dcgm:
```
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods -n monitoring -l "app.kubernetes.io/name=dcgm-exporter,app.kubernetes.io/instance=dcgm-exporter" -o jsonpath="{.items[0].metadata.name}")
  kubectl -n monitoring port-forward $POD_NAME 8080:9400 &
  echo "Visit http://127.0.0.1:8080/metrics to use your application"
```

drain in order to remove instance
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data --disable-eviction --force