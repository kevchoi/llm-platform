services:
  tgi-server:
    image: ghcr.io/huggingface/text-generation-inference:3.3.5
    command: --model-id meta-llama/Llama-3.2-1B # port is 3000; prometheus port is 9000?
    volumes: ./data:/data
    ports:
      - "8080:80"
      - "8081:8081"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  node-exporter:
    image: prom/node-exporter:latest
    command:
      - '--path.rootfs=/host'
    volumes:
      - '/:/host:ro,rslave' # exposes the root filesystem; instead of just /proc and /sys
    network_mode: host
    pid: host
    ports:
      - "9100:9100"